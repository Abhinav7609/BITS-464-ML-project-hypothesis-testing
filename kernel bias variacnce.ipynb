{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "# Create synthetic dataset\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 2)\n",
    "y = np.where(X[:, 0] + X[:, 1] > 1, 1, 0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create SVM models with different kernels\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_poly = SVC(kernel='poly', degree=3)\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# Train the models\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "y_pred_poly = svm_poly.predict(X_test)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "acc_linear = accuracy_score(y_test, y_pred_linear)\n",
    "acc_poly = accuracy_score(y_test, y_pred_poly)\n",
    "acc_rbf = accuracy_score(y_test, y_pred_rbf)\n",
    "\n",
    "print(f'Accuracy (Linear Kernel): {acc_linear}')\n",
    "print(f'Accuracy (Polynomial Kernel): {acc_poly}')\n",
    "print(f'Accuracy (RBF Kernel): {acc_rbf}')\n",
    "\n",
    "models = [svm_linear, svm_poly, svm_rbf]\n",
    "model_names = ['Linear Kernel', 'Polynomial Kernel', 'RBF Kernel']\n",
    "\n",
    "# Compute bias and variance for each model\n",
    "bias_squared = []\n",
    "variance = []\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='0-1_loss', num_rounds=200, random_seed=0)\n",
    "    print(f'Model: {name}')\n",
    "    print(f'Average Expected Loss: {avg_expected_loss}')\n",
    "    print(f'Average Bias^2: {avg_bias}')\n",
    "    print(f'Average Variance: {avg_var}')\n",
    "    print()\n",
    "\n",
    "    bias_squared.append(avg_bias)\n",
    "    variance.append(avg_var)\n",
    "\n",
    "# Plotting bias and variance against different kernels\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(model_names, bias_squared, marker='o', label='Bias^2')\n",
    "plt.plot(model_names, variance, marker='o', label='Variance')\n",
    "plt.xlabel('SVM Kernel')\n",
    "plt.ylabel('Bias^2 / Variance')\n",
    "plt.title('Bias-Variance vs SVM Kernel')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "\n",
    "# Create synthetic moon-shaped dataset\n",
    "X, y = make_moons(n_samples=100, noise=0.2, random_state=0)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create SVM models with different kernels\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_poly = SVC(kernel='poly', degree=3)\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "\n",
    "# Train the models\n",
    "svm_linear.fit(X_train, y_train)\n",
    "svm_poly.fit(X_train, y_train)\n",
    "svm_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Compute bias and variance for each model\n",
    "models = [svm_linear, svm_poly, svm_rbf]\n",
    "model_names = ['Linear Kernel', 'Polynomial Kernel', 'RBF Kernel']\n",
    "complexities = [1, 2, 3]  # Assigning complexity levels based on kernel types\n",
    "\n",
    "bias_squared = []\n",
    "variance = []\n",
    "\n",
    "for model, name, complexity in zip(models, model_names, complexities):\n",
    "    avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(model, X_train, y_train, X_test, y_test, loss='0-1_loss', num_rounds=200, random_seed=0)\n",
    "    print(f'Model: {name}')\n",
    "    print(f'Average Expected Loss: {avg_expected_loss}')\n",
    "    print(f'Average Bias^2: {avg_bias}')\n",
    "    print(f'Average Variance: {avg_var}')\n",
    "    print()\n",
    "\n",
    "    bias_squared.append(avg_bias)\n",
    "    variance.append(avg_var)\n",
    "\n",
    "# Plotting bias and variance against complexity\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(complexities, bias_squared, marker='o', label='Bias^2')\n",
    "plt.plot(complexities, variance, marker='o', label='Variance')\n",
    "plt.xlabel('Complexity (Kernel Type) ')\n",
    "plt.ylabel('Bias^2 / Variance')\n",
    "plt.title('Bias-Variance Tradeoff for SVM with moonshaped dataset')\n",
    "plt.xticks(complexities, model_names)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
